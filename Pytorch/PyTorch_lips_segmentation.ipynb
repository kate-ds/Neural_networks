{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-22T14:28:32.662283Z","iopub.execute_input":"2022-04-22T14:28:32.662597Z","iopub.status.idle":"2022-04-22T14:28:32.672240Z","shell.execute_reply.started":"2022-04-22T14:28:32.662563Z","shell.execute_reply":"2022-04-22T14:28:32.671285Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"## Подготовка датасета","metadata":{}},{"cell_type":"code","source":"!pip install segmentation-models-pytorch","metadata":{"execution":{"iopub.status.busy":"2022-04-22T14:28:33.381129Z","iopub.execute_input":"2022-04-22T14:28:33.381712Z","iopub.status.idle":"2022-04-22T14:28:46.379709Z","shell.execute_reply.started":"2022-04-22T14:28:33.381675Z","shell.execute_reply":"2022-04-22T14:28:46.378874Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport cv2\nimport warnings\n\nfrom PIL import Image\nimport segmentation_models_pytorch as smp\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.model_selection import train_test_split\n\nimport torch\nfrom torch.nn import functional as F\n\nwarnings.simplefilter(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2022-04-22T15:02:14.638328Z","iopub.execute_input":"2022-04-22T15:02:14.638594Z","iopub.status.idle":"2022-04-22T15:02:14.643990Z","shell.execute_reply.started":"2022-04-22T15:02:14.638565Z","shell.execute_reply":"2022-04-22T15:02:14.642977Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"DATA_ROOT = '/kaggle/input/makeup-lips-segmentation-28k-samples/set-lipstick-original/'","metadata":{"execution":{"iopub.status.busy":"2022-04-22T15:02:14.908600Z","iopub.execute_input":"2022-04-22T15:02:14.908850Z","iopub.status.idle":"2022-04-22T15:02:14.912911Z","shell.execute_reply.started":"2022-04-22T15:02:14.908821Z","shell.execute_reply":"2022-04-22T15:02:14.911899Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(1,2, figsize = (15,7))\n\nax[0].imshow(Image.open(DATA_ROOT + 'mask/mask00000777.png'))\nax[1].imshow(Image.open(DATA_ROOT + '720p/image00000777.jpg'))\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-22T15:02:15.120622Z","iopub.execute_input":"2022-04-22T15:02:15.120834Z","iopub.status.idle":"2022-04-22T15:02:15.611645Z","shell.execute_reply.started":"2022-04-22T15:02:15.120808Z","shell.execute_reply":"2022-04-22T15:02:15.610842Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(DATA_ROOT + 'list.csv')\ndf.tail()","metadata":{"execution":{"iopub.status.busy":"2022-04-22T15:02:15.613185Z","iopub.execute_input":"2022-04-22T15:02:15.613529Z","iopub.status.idle":"2022-04-22T15:02:15.670027Z","shell.execute_reply.started":"2022-04-22T15:02:15.613489Z","shell.execute_reply":"2022-04-22T15:02:15.669209Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"lips_pics = []\nlips_mask = []\nmasks_names = []\n\nfor root, dirs, files in os.walk(DATA_ROOT + '720p/'):\n    for name in files:\n        f = os.path.join(root, name)\n        lips_pics.append(f)\n\nfor root, dirs, files in os.walk(DATA_ROOT + 'mask/'):\n     for name in files:\n        f = os.path.join(root, name)\n        lips_mask.append(f)\n        masks_names.append(name)\n        \nlen(lips_pics), len(lips_mask), len(masks_names)","metadata":{"execution":{"iopub.status.busy":"2022-04-22T15:02:15.982318Z","iopub.execute_input":"2022-04-22T15:02:15.982583Z","iopub.status.idle":"2022-04-22T15:02:26.319584Z","shell.execute_reply.started":"2022-04-22T15:02:15.982553Z","shell.execute_reply":"2022-04-22T15:02:26.318833Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"IMG_PATH = '/kaggle/input/makeup-lips-segmentation-28k-samples/set-lipstick-original/720p/'\nMASK_PATH = '/kaggle/input/makeup-lips-segmentation-28k-samples/set-lipstick-original/mask/'","metadata":{"execution":{"iopub.status.busy":"2022-04-22T15:02:26.321180Z","iopub.execute_input":"2022-04-22T15:02:26.321520Z","iopub.status.idle":"2022-04-22T15:02:26.327663Z","shell.execute_reply.started":"2022-04-22T15:02:26.321480Z","shell.execute_reply":"2022-04-22T15:02:26.326869Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"lips_pics[:5] , lips_mask[:5], masks_names[:5]","metadata":{"execution":{"iopub.status.busy":"2022-04-22T15:02:26.330560Z","iopub.execute_input":"2022-04-22T15:02:26.330970Z","iopub.status.idle":"2022-04-22T15:02:26.338917Z","shell.execute_reply.started":"2022-04-22T15:02:26.330932Z","shell.execute_reply":"2022-04-22T15:02:26.338057Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"df_2 = df.loc[df['mask'].isin([mask for mask in masks_names])]\nprint(f\"Было : {df.shape}, \\nСтало: {df_2.shape}\")","metadata":{"execution":{"iopub.status.busy":"2022-04-22T15:02:26.341058Z","iopub.execute_input":"2022-04-22T15:02:26.341380Z","iopub.status.idle":"2022-04-22T15:02:26.370336Z","shell.execute_reply.started":"2022-04-22T15:02:26.341347Z","shell.execute_reply":"2022-04-22T15:02:26.369511Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"df_2['filename'] = IMG_PATH + df_2['filename']\ndf_2['mask'] = MASK_PATH + df_2['mask']\n\ndf_2.head(2)","metadata":{"execution":{"iopub.status.busy":"2022-04-22T15:02:26.372352Z","iopub.execute_input":"2022-04-22T15:02:26.373086Z","iopub.status.idle":"2022-04-22T15:02:26.399666Z","shell.execute_reply.started":"2022-04-22T15:02:26.373038Z","shell.execute_reply":"2022-04-22T15:02:26.398891Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"class LipsDataset(Dataset):\n    \n    def __init__(self, data, preprocessing=None):\n        self.data = data\n        \n        self.image_arr = self.data['filename']\n        self.label_arr = self.data['mask']\n\n        self.data_len = len(self.data.index)\n        \n        self.preprocessing = preprocessing\n        \n    def __getitem__(self, index):\n\n        img = cv2.cvtColor(cv2.imread(self.image_arr[index]), cv2.COLOR_RGB2BGR)\n        img = cv2.resize(img, (256, 256))\n        img = np.array(img).astype('float')\n        \n        if self.preprocessing:\n            img = self.preprocessing(img)\n            img = torch.as_tensor(img)\n        else:\n            # Нормализуем изображение в значениях [0, 1]\n            img = torch.as_tensor(img) / 255.0\n        \n        img = img.permute(2,0,1)\n        \n#         print(self.label_arr[index])\n        mask = cv2.cvtColor(cv2.imread(self.label_arr[index]), cv2.COLOR_BGR2RGB)\n#         print(mask)\n        mask = cv2.resize(mask, (256, 256))\n        mask = np.array(mask).astype('float')\n            \n        mask = torch.as_tensor(mask)/255.0  \n        mask = mask.permute(2,0,1)\n                   \n        return (img.float(), mask)\n\n    def __len__(self):\n        return self.data_len","metadata":{"execution":{"iopub.status.busy":"2022-04-22T15:02:26.401119Z","iopub.execute_input":"2022-04-22T15:02:26.401539Z","iopub.status.idle":"2022-04-22T15:02:26.413802Z","shell.execute_reply.started":"2022-04-22T15:02:26.401506Z","shell.execute_reply":"2022-04-22T15:02:26.413066Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"dataset = LipsDataset(df_2)\nimg, masks = dataset[42]\nprint(img.shape, masks.shape)\nfig, ax = plt.subplots(1, 2, figsize=(15, 7))\nax[0].imshow(img.permute(1, 2, 0))\nax[1].imshow(masks.permute(1, 2, 0))\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-22T15:02:26.415050Z","iopub.execute_input":"2022-04-22T15:02:26.415467Z","iopub.status.idle":"2022-04-22T15:02:26.818482Z","shell.execute_reply.started":"2022-04-22T15:02:26.415432Z","shell.execute_reply":"2022-04-22T15:02:26.817826Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\ndevice","metadata":{"execution":{"iopub.status.busy":"2022-04-22T15:02:26.819903Z","iopub.execute_input":"2022-04-22T15:02:26.820408Z","iopub.status.idle":"2022-04-22T15:02:26.826676Z","shell.execute_reply.started":"2022-04-22T15:02:26.820369Z","shell.execute_reply":"2022-04-22T15:02:26.825915Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"# создание модели\nBACKBONE = 'resnet34'\nsegmodel = smp.Unet(BACKBONE, classes=1, activation='sigmoid').to(device)\npreprocess_input = smp.encoders.get_preprocessing_fn(BACKBONE, pretrained='imagenet')","metadata":{"execution":{"iopub.status.busy":"2022-04-22T15:02:26.827988Z","iopub.execute_input":"2022-04-22T15:02:26.828924Z","iopub.status.idle":"2022-04-22T15:02:27.499445Z","shell.execute_reply.started":"2022-04-22T15:02:26.828887Z","shell.execute_reply":"2022-04-22T15:02:27.498609Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"train, test =  train_test_split(df_2, test_size=0.3 ,random_state=42)\n\ntrain.reset_index(drop=True, inplace=True)\ntest.reset_index(drop=True, inplace=True)\n\ndf_train = LipsDataset(train, preprocessing=preprocess_input)\ndf_test = LipsDataset(test, preprocessing=preprocess_input)\n\ntrain_data_loader = DataLoader(df_train, batch_size=30, shuffle=True)\ntest_data_loader = DataLoader(df_test, batch_size=10, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2022-04-22T15:02:27.501822Z","iopub.execute_input":"2022-04-22T15:02:27.502318Z","iopub.status.idle":"2022-04-22T15:02:27.520344Z","shell.execute_reply.started":"2022-04-22T15:02:27.502277Z","shell.execute_reply":"2022-04-22T15:02:27.519290Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"for img, target in train_data_loader:\n    print(img.shape, target.shape)\n    print(img[0].min(), img[0].max())\n    print(target[0].min(), target[0].max())\n    fig, ax = plt.subplots(1, 2, figsize=(15, 6))\n    ax[0].imshow(img[0].permute(1, 2, 0))\n    ax[1].imshow(target[0].permute(1, 2, 0)[..., 0])\n    break","metadata":{"execution":{"iopub.status.busy":"2022-04-22T15:02:27.524510Z","iopub.execute_input":"2022-04-22T15:02:27.524788Z","iopub.status.idle":"2022-04-22T15:02:28.715345Z","shell.execute_reply.started":"2022-04-22T15:02:27.524755Z","shell.execute_reply":"2022-04-22T15:02:28.714643Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"criterion = smp.utils.losses.DiceLoss()\nmetrics = [smp.utils.metrics.IoU(),]\n\noptimizer = torch.optim.Adam(params=segmodel.parameters(), lr=0.001)","metadata":{"execution":{"iopub.status.busy":"2022-04-22T15:02:28.716599Z","iopub.execute_input":"2022-04-22T15:02:28.716828Z","iopub.status.idle":"2022-04-22T15:02:28.722654Z","shell.execute_reply.started":"2022-04-22T15:02:28.716795Z","shell.execute_reply":"2022-04-22T15:02:28.721742Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"train_epoch = smp.utils.train.TrainEpoch(\n    segmodel, \n    loss=criterion, \n    metrics=metrics, \n    optimizer=optimizer,\n    device=device,\n    verbose=True,\n)\n\nvalid_epoch = smp.utils.train.ValidEpoch(\n    segmodel, \n    loss=criterion, \n    metrics=metrics, \n    device=device,\n    verbose=True,\n)","metadata":{"execution":{"iopub.status.busy":"2022-04-22T15:02:28.723854Z","iopub.execute_input":"2022-04-22T15:02:28.724267Z","iopub.status.idle":"2022-04-22T15:02:28.737676Z","shell.execute_reply.started":"2022-04-22T15:02:28.724231Z","shell.execute_reply":"2022-04-22T15:02:28.737078Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"# train model\nepoch = 5\nmax_score = 0\n\nfor i in range(epoch):\n    print(f'Epoch: {i + 1}')\n    train_logs = train_epoch.run(train_data_loader)\n    valid_logs = valid_epoch.run(test_data_loader)\n    \n    # do something (save model, change lr, etc.)\n    if max_score < valid_logs['iou_score']:\n        max_score = valid_logs['iou_score']\n        torch.save(segmodel, './best_model.pth')\n        print('Model saved!')","metadata":{"execution":{"iopub.status.busy":"2022-04-22T15:02:28.738637Z","iopub.execute_input":"2022-04-22T15:02:28.739182Z","iopub.status.idle":"2022-04-22T16:19:20.672659Z","shell.execute_reply.started":"2022-04-22T15:02:28.739135Z","shell.execute_reply":"2022-04-22T16:19:20.671820Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"class_idx = 1\n\nfor i, data in enumerate(test_data_loader):\n    images, labels = data\n    images = images.to(device)\n    labels = labels.to(device)\n    outputs = segmodel(images)\n    fig , ax = plt.subplots(1, 3, figsize=(16,5))\n\n    for j in range(3):\n\n        image = images[i].permute(1, 2, 0)\n        label = labels[i]\n\n        ax[0].imshow(image.cpu())\n        ax[0].set_title('Image')\n        \n        ax[1].imshow(outputs.detach().cpu()[i].permute(1, 2, 0))\n        ax[1].set_title('Pred_mask')\n\n        ax[2].imshow(label.cpu().permute(1, 2, 0))\n        ax[2].set_title('True_mask')\n        \n    if i > 1:\n        break","metadata":{"execution":{"iopub.status.busy":"2022-04-22T16:22:18.923503Z","iopub.execute_input":"2022-04-22T16:22:18.923764Z","iopub.status.idle":"2022-04-22T16:22:21.551608Z","shell.execute_reply.started":"2022-04-22T16:22:18.923735Z","shell.execute_reply":"2022-04-22T16:22:21.550911Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}